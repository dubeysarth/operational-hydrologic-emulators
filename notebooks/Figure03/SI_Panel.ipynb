{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Setting Up\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import xesmf as xe\n",
    "import networkx as nx\n",
    "# import rioxarray as rxr\n",
    "\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import tqdm\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "\n",
    "import configparser\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.optionxform = str\n",
    "cfg.read('/home/sarth/rootdir/datadir/assets/defaults.ini')\n",
    "cfg = {s: dict(cfg.items(s)) for s in cfg.sections()}\n",
    "PATHS = cfg['PATHS']\n",
    "\n",
    "print(\"Setting up...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats, signal\n",
    "\n",
    "def _mask_valid(pred, true):\n",
    "    mask = ~np.isnan(true) & ~np.isnan(pred)\n",
    "    pred = pred[mask]\n",
    "    true = true[mask]\n",
    "    pred[pred < 0] = 0\n",
    "    true[true < 0] = 0\n",
    "    return pred, true\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    return np.sqrt(np.mean((true - pred)**2))\n",
    "\n",
    "def pearsonr(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    r, _ = stats.pearsonr(true, pred)\n",
    "    return r\n",
    "\n",
    "def NSE(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    return 1 - np.sum((true - pred)**2) / np.sum((true - np.mean(true))**2)\n",
    "\n",
    "def KGE(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    r = pearsonr(pred, true)\n",
    "    alpha = np.std(pred) / np.std(true)\n",
    "    beta = np.mean(pred) / np.mean(true)\n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "def PBIAS(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    return np.sum(true - pred) / np.sum(true) * 100\n",
    "\n",
    "def alpha_NSE(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    return np.std(pred) / np.std(true)\n",
    "\n",
    "def beta_NSE(pred, true):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "    return (np.mean(pred) - np.mean(true)) / np.std(true)\n",
    "\n",
    "def _get_fdc(data):\n",
    "    data = np.sort(data)[::-1]\n",
    "    return data\n",
    "\n",
    "def fdc_fms(pred, true, lower = 0.2, upper = 0.7):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    sim = _get_fdc(pred)\n",
    "    obs = _get_fdc(true)\n",
    "    sim[sim <= 0] = 1e-6\n",
    "    obs[obs <= 0] = 1e-6\n",
    "\n",
    "    qsm_lower = np.log(sim[np.round(lower * len(sim)).astype(int)])\n",
    "    qsm_upper = np.log(sim[np.round(upper * len(sim)).astype(int)])\n",
    "    qom_lower = np.log(obs[np.round(lower * len(obs)).astype(int)])\n",
    "    qom_upper = np.log(obs[np.round(upper * len(obs)).astype(int)])\n",
    "\n",
    "    fms = ((qsm_lower - qsm_upper) - (qom_lower - qom_upper)) / (qom_lower - qom_upper + 1e-6)\n",
    "\n",
    "    return fms * 100\n",
    "\n",
    "def fdc_fhv(pred, true, h = 0.02):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    sim = _get_fdc(pred)\n",
    "    obs = _get_fdc(true)\n",
    "\n",
    "    obs = obs[:np.round(h * len(obs)).astype(int)]\n",
    "    sim = sim[:np.round(h * len(sim)).astype(int)]\n",
    "\n",
    "    fhv = np.sum(sim - obs) / np.sum(obs)\n",
    "\n",
    "    return fhv * 100\n",
    "\n",
    "def fdc_flv(pred, true, l = 0.3):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    sim = _get_fdc(pred)\n",
    "    obs = _get_fdc(true)\n",
    "    sim[sim <= 0] = 1e-6\n",
    "    obs[obs <= 0] = 1e-6\n",
    "\n",
    "    obs = obs[-np.round(l * len(obs)).astype(int):]\n",
    "    sim = sim[-np.round(l * len(sim)).astype(int):]\n",
    "\n",
    "    # transform values to log scale\n",
    "    obs = np.log(obs)\n",
    "    sim = np.log(sim)\n",
    "\n",
    "    # calculate flv part by part\n",
    "    qsl = np.sum(sim - sim.min())\n",
    "    qol = np.sum(obs - obs.min())\n",
    "\n",
    "    flv = -1 * (qsl - qol) / (qol + 1e-6)\n",
    "\n",
    "    return flv * 100\n",
    "\n",
    "def mean_peak_timing(pred, true, window = 3):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(true, distance=2*window, prominence=np.std(true))\n",
    "\n",
    "    # pred_idx_lst = []\n",
    "    timing_error_lst = []\n",
    "    for idx in peaks:\n",
    "        if (pred[idx] > pred[idx - 1]) and (pred[idx] > pred[idx + 1]):\n",
    "            peak_pred = pred[idx]\n",
    "            peak_pred_idx = idx\n",
    "        else:\n",
    "            peak_pred_idx = np.argmax(pred[max(idx - window,0):idx + window + 1]) + max(idx - window,0)\n",
    "            peak_pred = pred[peak_pred_idx]\n",
    "        # pred_idx_lst.append(peak_pred_idx)\n",
    "    \n",
    "        peak_true = true[idx]\n",
    "        timing_error = np.abs(peak_pred_idx - idx) \n",
    "        timing_error_lst.append(timing_error)\n",
    "    \n",
    "    mean_timing_error = np.mean(timing_error_lst) if len(timing_error_lst) > 0 else np.nan\n",
    "\n",
    "    return mean_timing_error\n",
    "\n",
    "def missed_peaks(pred, true, window = 3, threshold = 80):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    peaks_obs_times, _ = signal.find_peaks(true, distance=2*window, height = np.percentile(true, threshold))\n",
    "    peaks_sim_times, _ = signal.find_peaks(pred, distance=2*window, height = np.percentile(pred, threshold))\n",
    "    \n",
    "    missed_events = 0\n",
    "    for idx in peaks_obs_times:\n",
    "        nearby_peak_sim_index = np.where(np.abs(peaks_sim_times - idx) <= window)[0]\n",
    "        if len(nearby_peak_sim_index) == 0:\n",
    "            missed_events += 1\n",
    "            # print(idx)\n",
    "    \n",
    "    missed_peak_values = (missed_events / len(peaks_obs_times)) * 100 if len(peaks_obs_times) > 0 else np.nan\n",
    "\n",
    "    return missed_peak_values\n",
    "\n",
    "def F1_score_of_capturing_peaks(pred, true, window = 3, threshold = 80):\n",
    "    pred, true = _mask_valid(pred, true)\n",
    "\n",
    "    peaks_obs_times, _ = signal.find_peaks(true, distance=2*window, height = np.percentile(true, threshold))\n",
    "    peaks_sim_times, _ = signal.find_peaks(pred, distance=2*window, height = np.percentile(pred, threshold))\n",
    "    \n",
    "    true_positive_peaks = 0 # peak in obs and nearby in sim\n",
    "    true_negative_peaks = 0 # no peak in obs and sim\n",
    "    false_positive_peaks = 0 # peak in sim but not nearby in obs\n",
    "    false_negative_peaks = 0 # peak in obs but not nearby in sim\n",
    "\n",
    "    for idx in peaks_obs_times:\n",
    "        nearby_peak_sim_index = np.where(np.abs(peaks_sim_times - idx) <= window)[0]\n",
    "        if len(nearby_peak_sim_index) > 0:\n",
    "            true_positive_peaks += 1\n",
    "        else:\n",
    "            false_negative_peaks += 1\n",
    "    \n",
    "    for idx in peaks_sim_times:\n",
    "        nearby_peak_obs_index = np.where(np.abs(peaks_obs_times - idx) <= window)[0]\n",
    "        if len(nearby_peak_obs_index) == 0:\n",
    "            false_positive_peaks += 1\n",
    "\n",
    "    precision = true_positive_peaks / (true_positive_peaks + false_positive_peaks) if (true_positive_peaks + false_positive_peaks) > 0 else np.nan\n",
    "    recall = true_positive_peaks / (true_positive_peaks + false_negative_peaks) if (true_positive_peaks + false_negative_peaks) > 0 else np.nan\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else np.nan\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def compute_metrics_ds(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Compute a set of metrics for each lead time and catchment.\n",
    "    y_pred and y_true: numpy arrays of shape (time_idx, lead_time, catmt_idx)\n",
    "    \n",
    "    Returns:\n",
    "      xr.Dataset with dims (\"time_idx\", \"lead_time\", \"catmt_idx\") and variables:\n",
    "          - RMSE, PearsonR, NSE, KGE, PBIAS, alpha_NSE, beta_NSE,\n",
    "            FDC_FMS, FDC_FHV, FDC_FLV, mean_peak_timing, missed_peaks, F1_score\n",
    "          - Also includes raw y_pred and y_true.\n",
    "    \"\"\"\n",
    "\n",
    "    time_steps, num_leadtimes, num_catmt = y_pred.shape\n",
    "\n",
    "    # Prepare arrays to hold computed metrics [lead_time, catmt_idx]\n",
    "    rmse_arr            = np.empty((num_leadtimes, num_catmt))\n",
    "    pearson_arr         = np.empty((num_leadtimes, num_catmt))\n",
    "    nse_arr             = np.empty((num_leadtimes, num_catmt))\n",
    "    kge_arr             = np.empty((num_leadtimes, num_catmt))\n",
    "    pbias_arr           = np.empty((num_leadtimes, num_catmt))\n",
    "    alpha_nse_arr       = np.empty((num_leadtimes, num_catmt))\n",
    "    beta_nse_arr        = np.empty((num_leadtimes, num_catmt))\n",
    "    fdc_fms_arr         = np.empty((num_leadtimes, num_catmt))\n",
    "    fdc_fhv_arr         = np.empty((num_leadtimes, num_catmt))\n",
    "    fdc_flv_arr         = np.empty((num_leadtimes, num_catmt))\n",
    "    mean_peak_timing_arr= np.empty((num_leadtimes, num_catmt))\n",
    "    missed_peaks_arr    = np.empty((num_leadtimes, num_catmt))\n",
    "    f1_score_arr        = np.empty((num_leadtimes, num_catmt))\n",
    "\n",
    "    # Loop over lead times and catchments, computing metrics from the time series\n",
    "    for lt in range(num_leadtimes):\n",
    "        for cat in range(num_catmt):\n",
    "            pred = y_pred[:, lt, cat]\n",
    "            true = y_true[:, lt, cat]\n",
    "            rmse_arr[lt, cat]             = RMSE(pred, true)\n",
    "            pearson_arr[lt, cat]          = pearsonr(pred, true)\n",
    "            nse_arr[lt, cat]              = NSE(pred, true)\n",
    "            kge_arr[lt, cat]              = KGE(pred, true)\n",
    "            pbias_arr[lt, cat]            = PBIAS(pred, true)\n",
    "            alpha_nse_arr[lt, cat]        = alpha_NSE(pred, true)\n",
    "            beta_nse_arr[lt, cat]         = beta_NSE(pred, true)\n",
    "            fdc_fms_arr[lt, cat]          = fdc_fms(pred, true)\n",
    "            fdc_fhv_arr[lt, cat]          = fdc_fhv(pred, true)\n",
    "            fdc_flv_arr[lt, cat]          = fdc_flv(pred, true)\n",
    "            mean_peak_timing_arr[lt, cat] = mean_peak_timing(pred, true)\n",
    "            missed_peaks_arr[lt, cat]     = missed_peaks(pred, true)\n",
    "            f1_score_arr[lt, cat]         = F1_score_of_capturing_peaks(pred, true)\n",
    "\n",
    "    # Create coordinates\n",
    "    lead_times = np.arange(num_leadtimes)\n",
    "    catmt_idx  = np.arange(num_catmt)\n",
    "    time_idx   = np.arange(time_steps)\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"RMSE\":             ((\"lead_time\", \"catmt_idx\"), rmse_arr),\n",
    "            \"PearsonR\":         ((\"lead_time\", \"catmt_idx\"), pearson_arr),\n",
    "            \"NSE\":              ((\"lead_time\", \"catmt_idx\"), nse_arr),\n",
    "            \"KGE\":              ((\"lead_time\", \"catmt_idx\"), kge_arr),\n",
    "            \"PBIAS\":            ((\"lead_time\", \"catmt_idx\"), pbias_arr),\n",
    "            \"alpha_NSE\":        ((\"lead_time\", \"catmt_idx\"), alpha_nse_arr),\n",
    "            \"beta_NSE\":         ((\"lead_time\", \"catmt_idx\"), beta_nse_arr),\n",
    "            \"FDC_FMS\":          ((\"lead_time\", \"catmt_idx\"), fdc_fms_arr),\n",
    "            \"FDC_FHV\":          ((\"lead_time\", \"catmt_idx\"), fdc_fhv_arr),\n",
    "            \"FDC_FLV\":          ((\"lead_time\", \"catmt_idx\"), fdc_flv_arr),\n",
    "            \"mean_peak_timing\": ((\"lead_time\", \"catmt_idx\"), mean_peak_timing_arr),\n",
    "            \"missed_peaks\":     ((\"lead_time\", \"catmt_idx\"), missed_peaks_arr),\n",
    "            \"F1_score\":         ((\"lead_time\", \"catmt_idx\"), f1_score_arr),\n",
    "            \"y_pred\":           ((\"time_idx\", \"lead_time\", \"catmt_idx\"), y_pred),\n",
    "            \"y_true\":           ((\"time_idx\", \"lead_time\", \"catmt_idx\"), y_true)\n",
    "        },\n",
    "        coords={\n",
    "            \"time_idx\": time_idx,\n",
    "            \"lead_time\": lead_times,\n",
    "            \"catmt_idx\": catmt_idx\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# # Example usage:\n",
    "# metrics_ds = compute_metrics_ds(y_pred, y_true)\n",
    "# metrics_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = lambda x, region: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure03', f'v{x}_surr_{region}_test.pt')\n",
    "\n",
    "version = 1\n",
    "region = 'camelsus'\n",
    "\n",
    "saved_tensor = torch.load(filepath(version, region))\n",
    "\n",
    "for key in saved_tensor.keys():\n",
    "    print(key, saved_tensor[key].shape)\n",
    "\n",
    "y_pred = saved_tensor['pred_tensor'].numpy()\n",
    "y_true = saved_tensor['true_tensor'].numpy()\n",
    "\n",
    "metrics = compute_metrics_ds(y_pred, y_true)\n",
    "metrics.to_netcdf(filepath(version, region).replace('.pt', '_metrics.nc'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "region = 'camelsus'\n",
    "for version in [1, 2, 3, 4]:\n",
    "    for region in ['camelsus', 'camelsind', 'hysets']: \n",
    "        if os.path.exists(filepath(version, region).replace('.pt', '_metrics.nc')):\n",
    "            print(f\"Skipping version {version}, region {region}\")\n",
    "        else:\n",
    "            print(f\"Processing version {version}, region {region}\")\n",
    "            saved_tensor = torch.load(filepath(version, region))\n",
    "            # for key in saved_tensor.keys():\n",
    "            #     print(key, saved_tensor[key].shape)\n",
    "            y_pred = saved_tensor['pred_tensor'].numpy()\n",
    "            y_true = saved_tensor['true_tensor'].numpy()\n",
    "            metrics = compute_metrics_ds(y_pred, y_true)\n",
    "            metrics.to_netcdf(filepath(version, region).replace('.pt', '_metrics.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_metric_performance(metric_name, ds, lead_time=1, cmap_name='viridis', min_max=None, watersheds_local=None, camels_graph_local=None, metric_label=None, extend=None):\n",
    "    \"\"\"\n",
    "    Plot regional performance based on a metric and gauge-level performance.\n",
    "\n",
    "    Parameters:\n",
    "      metric_name: str, name of the metric in ds (expected dims: [lead_time, catmt_idx])\n",
    "      ds: xarray.Dataset containing the metric array\n",
    "      lead_time: int, which lead time to use (default: 1 corresponds to the first lead time)\n",
    "      cmap_name: str, name of the colormap (default: 'viridis')\n",
    "      min_max: list [vmin, vmax] to fix the colormap range; if None, get min and max from combined data.\n",
    "    \"\"\"\n",
    "    # Select the metric values for the desired lead time (assume 1-indexed)\n",
    "    metric_vals = ds[metric_name].isel(lead_time=lead_time-1).values  # shape: (catmt_idx,)\n",
    "    gauge_metric = metric_vals  # already 1-D for selected lead time\n",
    "\n",
    "    # Append selected metric to camels_graph (assuming order matches ds catmt_idx)\n",
    "    # camels_graph_local = catmt_graph.copy()\n",
    "    camels_graph_local['metric'] = gauge_metric\n",
    "\n",
    "    # Compute regional median per watershed (using huc_02 field)\n",
    "    region_median = camels_graph_local.groupby('huc_02')['metric'].median()\n",
    "    # Merge with all_watersheds: assume all_watersheds has column \"huc_02\" \n",
    "    # watersheds_local = all_watersheds.copy()\n",
    "    watersheds_local['region_metric'] = watersheds_local['huc_02'].map(region_median)\n",
    "    \n",
    "    # Determine vmin, vmax for normalization\n",
    "    if min_max is None:\n",
    "        all_values = np.concatenate([watersheds_local['region_metric'].dropna().values,\n",
    "                                     camels_graph_local['metric'].values])\n",
    "        vmin, vmax = np.nanmin(all_values), np.nanmax(all_values)\n",
    "    else:\n",
    "        vmin, vmax = min_max\n",
    "\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cmap = cm.get_cmap(cmap_name)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), dpi=600)\n",
    "\n",
    "    # Plot regions (all_watersheds) with fill based on regional median\n",
    "    watersheds_local.plot(\n",
    "        column='region_metric',\n",
    "        ax=ax,\n",
    "        cmap=cmap_name,\n",
    "        norm=norm,\n",
    "        edgecolor='gray',\n",
    "        linewidth=0.5,\n",
    "        alpha=0.70,\n",
    "        legend=False  # add colorbar separately\n",
    "    )\n",
    "    \n",
    "    # Scatter plot for gauge locations: use the gauge metric to set facecolor\n",
    "    scatter = ax.scatter(\n",
    "        camels_graph_local['gauge_lon'],\n",
    "        camels_graph_local['gauge_lat'],\n",
    "        c=camels_graph_local['metric'],\n",
    "        cmap=cmap_name,\n",
    "        norm=norm,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.3,\n",
    "        s=30,\n",
    "        marker='^',\n",
    "        alpha=0.70\n",
    "    )\n",
    "    \n",
    "    # Add a clean colorbar\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    if extend is None:\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', pad=0, shrink=0.75, aspect=50)\n",
    "    else:\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='horizontal', pad=0, shrink=0.75, aspect=50, extend=extend)\n",
    "\n",
    "    if metric_label is None:\n",
    "        metric_label = metric_name\n",
    "    \n",
    "    cbar.set_label(metric_label, fontsize=32)\n",
    "    cbar.ax.tick_params(labelsize=24, rotation=45)\n",
    "    \n",
    "    # Aesthetics\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax#, (camels_graph_local, region_median, watersheds_local)\n",
    "\n",
    "# Example usage:\n",
    "# fig, ax = plot_metric_performance('NSE', metrics_v1, lead_time=1, cmap_name='plasma', min_max=None)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMELS-US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Region-Specific: CAMELS-US\n",
    "DIRNAME = '03min_GloFAS_CAMELS-US'\n",
    "SAVE_PATH = os.path.join(PATHS['devp_datasets'], DIRNAME)\n",
    "resolution = 0.05\n",
    "lon_360_180 = lambda x: (x + 180) % 360 - 180 # convert 0-360 to -180-180\n",
    "lon_180_360 = lambda x: x % 360 # convert -180-180 to 0-360\n",
    "region_bounds = {\n",
    "    'minx': -130,\n",
    "    'miny': 20,\n",
    "    'maxx': -65,\n",
    "    'maxy': 50\n",
    "}\n",
    "camels_attributes_graph = pd.read_csv(os.path.join(SAVE_PATH, 'graph_attributes.csv'), index_col=0)\n",
    "camels_attributes_graph.index = camels_attributes_graph.index.map(lambda x: str(x).zfill(8))\n",
    "camels_attributes_graph['huc_02'] = camels_attributes_graph['huc_02'].map(lambda x: str(x).zfill(2))\n",
    "camels_graph = camels_attributes_graph.copy()\n",
    "camels_graph = camels_graph[camels_graph['area_percent_difference'] < 10]\n",
    "camels_graph = camels_graph[camels_graph['num_nodes'] > 1]\n",
    "print(f\"Number of CAMELS-US catmt's: {len(camels_graph)}\")\n",
    "del camels_attributes_graph\n",
    "\n",
    "region_shp = gpd.read_file(os.path.join(PATHS['watershed-boundary-dataset'], 'huc02', 'shapefile.shp'), crs = 'epsg:4326')\n",
    "all_watersheds = region_shp.copy()\n",
    "all_watersheds = all_watersheds.rename(columns={'huc2': 'watershed'})\n",
    "all_watersheds['huc_02'] = all_watersheds['watershed'].map(lambda x: x.split('_')[0])\n",
    "\n",
    "temp = gpd.read_file(os.path.join(PATHS['CAMELS'], 'CAMELS-US', 'HCDN_nhru_final_671.shp'), crs = 'epsg:4326')\n",
    "temp = temp[['hru_id', 'geometry']]\n",
    "temp['hru_id'] = temp['hru_id'].map(lambda x: str(x).zfill(8))\n",
    "temp = temp.set_index('hru_id')\n",
    "\n",
    "all_catchments = camels_graph.merge(temp, left_index=True, right_index=True, how='left')\n",
    "all_catchments = all_catchments[['huc_02', 'gauge_lon', 'gauge_lat', 'area_geospa_fabric', 'geometry', 'snapped_lon', 'snapped_lat']]\n",
    "all_catchments = gpd.GeoDataFrame(all_catchments, crs='epsg:4326', geometry='geometry')\n",
    "all_catchments = all_catchments.reset_index()\n",
    "del temp\n",
    "\n",
    "catmt_graph = camels_graph.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = lambda x, region: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure03', f'v{x}_surr_{region}_test_metrics.nc')\n",
    "ds = xr.open_dataset(filepath(2, 'camelsus'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('KGE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='KGE', extend='min')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PBIAS', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='PBIAS', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PearsonR', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='r', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('RMSE', ds, lead_time=1, cmap_name='RdYlBu_r', min_max=None, watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='RMSE', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('KGE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='KGE', extend='min')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PBIAS', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='PBIAS', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PearsonR', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='r', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('RMSE', ds, lead_time=1, cmap_name='RdYlBu_r', min_max=None, watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='RMSE', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FHV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FHV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FLV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-500,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FLV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FHV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FHV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FLV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-500,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FLV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('NSE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('F1_score', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMELS-IND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Region-Specific: CAMELS-IND\n",
    "DIRNAME = '03min_GloFAS_CAMELS-IND'\n",
    "SAVE_PATH = os.path.join(PATHS['devp_datasets'], DIRNAME)\n",
    "resolution = 0.05\n",
    "lon_360_180 = lambda x: (x + 180) % 360 - 180 # convert 0-360 to -180-180\n",
    "lon_180_360 = lambda x: x % 360 # convert -180-180 to 0-360\n",
    "region_bounds = {\n",
    "    'minx': 66,\n",
    "    'miny': 5,\n",
    "    'maxx': 100,\n",
    "    'maxy': 30\n",
    "}\n",
    "camels_attributes_graph = pd.read_csv(os.path.join(SAVE_PATH, 'graph_attributes.csv'), index_col=0)\n",
    "camels_attributes_graph.index = camels_attributes_graph.index.map(lambda x: str(x).zfill(5))\n",
    "camels_attributes_graph['huc_02'] = camels_attributes_graph['huc_02'].map(lambda x: str(x).zfill(2))\n",
    "camels_graph = camels_attributes_graph.copy()\n",
    "camels_graph = camels_graph[camels_graph['ghi_area'] <= 30000]\n",
    "camels_graph = camels_graph[camels_graph['area_percent_difference'] < 10]\n",
    "camels_graph = camels_graph[camels_graph['num_nodes'] > 1]\n",
    "camels_graph = camels_graph.rename(columns = {'ghi_lon': 'gauge_lon', 'ghi_lat': 'gauge_lat'})\n",
    "print(f\"Number of catmt's: {len(camels_graph)}\")\n",
    "del camels_attributes_graph\n",
    "\n",
    "all_watershed_names = sorted(glob.glob(os.path.join(PATHS['CAMELS'], 'CAMELS-IND', 'CAMELS_IND_All_Catchments', 'shapefiles_catchment', '*')))\n",
    "all_watershed_names = [x for x in all_watershed_names if os.path.isdir(x) and os.path.basename(x) != 'merged']\n",
    "all_watershed_shps = [os.path.join(x, os.path.basename(x) + '.shp') for x in all_watershed_names]\n",
    "all_watershed_shps = [gpd.read_file(x) for x in all_watershed_shps]\n",
    "all_watersheds = gpd.GeoDataFrame(pd.concat(all_watershed_shps, ignore_index=True))\n",
    "all_watersheds = all_watersheds.to_crs(epsg=4326)\n",
    "all_watersheds['watershed'] = [os.path.basename(x) for x in all_watershed_names]\n",
    "all_watersheds = all_watersheds[['watershed', 'geometry']]\n",
    "# all_watersheds.set_index('watershed', inplace=True)\n",
    "all_watersheds['huc_02'] = all_watersheds['watershed'].map(lambda x: x.split('_')[0])\n",
    "del all_watershed_shps, all_watershed_names\n",
    "\n",
    "# Create a union of all watershed geometries\n",
    "union_geom = all_watersheds['geometry'].unary_union\n",
    "# Create a GeoDataFrame with a single row containing the union geometry\n",
    "region_shp = gpd.GeoDataFrame({'huc_02': ['all'], 'geometry': [union_geom]},\n",
    "                              crs=all_watersheds.crs)\n",
    "del union_geom\n",
    "\n",
    "all_catchments = gpd.read_file(os.path.join(PATHS['CAMELS'], 'CAMELS-IND', 'CAMELS_IND_Catchments_Streamflow_Sufficient', 'shapefiles_catchment', 'catchments.shp'))\n",
    "all_catchments = all_catchments.to_crs(epsg=4326)\n",
    "all_catchments['huc_02'] = all_catchments['gauge_id'].map(lambda x: x[:2])\n",
    "# Merge camels_graph[['ghi_area']] with all_catchments using index of camels_graph which is gauge_id and gauge_id of all_catchments\n",
    "all_catchments = all_catchments.merge(camels_graph[['ghi_area']], left_on='gauge_id', right_index=True)\n",
    "all_catchments = all_catchments.sort_values(by = 'ghi_area', ascending = True).reset_index(drop = True)\n",
    "\n",
    "catmt_graph = camels_graph.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = lambda x, region: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure03', f'v{x}_surr_{region}_test_metrics.nc')\n",
    "ds = xr.open_dataset(filepath(2, 'camelsind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('KGE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='KGE', extend='min')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PBIAS', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='PBIAS', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PearsonR', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='r', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('RMSE', ds, lead_time=1, cmap_name='RdYlBu_r', min_max=None, watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='RMSE', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FHV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FHV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FLV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-500,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FLV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('NSE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('F1_score', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYSETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Region-Specific: hysets\n",
    "DIRNAME = '03min_GloFAS_hysets'\n",
    "SAVE_PATH = os.path.join(PATHS['devp_datasets'], DIRNAME)\n",
    "resolution = 0.05\n",
    "lon_360_180 = lambda x: (x + 180) % 360 - 180 # convert 0-360 to -180-180\n",
    "lon_180_360 = lambda x: x % 360 # convert -180-180 to 0-360\n",
    "region_bounds = {\n",
    "    'minx': -130,\n",
    "    'miny': 20,\n",
    "    'maxx': -65,\n",
    "    'maxy': 50\n",
    "}\n",
    "\n",
    "catmt_graph = pd.read_csv(os.path.join(SAVE_PATH, 'nested_gauges', 'graph_attributes_with_nesting.csv'))\n",
    "# catmt_graph.index = catmt_graph.index.map(lambda x: str(x).zfill(8))\n",
    "catmt_graph['huc_02'] = catmt_graph['huc_02'].map(lambda x: str(x).zfill(2))\n",
    "# catmt_graph = catmt_graph[catmt_graph['area_percent_difference'] < 10]\n",
    "# catmt_graph = catmt_graph[catmt_graph['num_nodes'] > 1]\n",
    "print(f\"Number of catmt's: {len(catmt_graph)}\")\n",
    "\n",
    "# catmt_graph = catmt_graph[catmt_graph['nesting'].isin(['nested_downstream'])]\n",
    "# catmt_graph = catmt_graph.reset_index()\n",
    "print(f\"Number of catmt's: {len(catmt_graph)}\")\n",
    "\n",
    "region_shp = gpd.read_file(os.path.join(PATHS['watershed-boundary-dataset'], 'huc02', 'shapefile.shp'), crs = 'epsg:4326')\n",
    "all_watersheds = region_shp.copy()\n",
    "all_watersheds = all_watersheds.rename(columns={'huc2': 'watershed'})\n",
    "all_watersheds['huc_02'] = all_watersheds['watershed'].map(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = lambda x, region: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure03', f'v{x}_surr_{region}_test_metrics.nc')\n",
    "ds = xr.open_dataset(filepath(2, 'hysets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('KGE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='KGE', extend='min')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PBIAS', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='PBIAS', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('PearsonR', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='r', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('RMSE', ds, lead_time=1, cmap_name='RdYlBu_r', min_max=None, watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='RMSE', extend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FHV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-100,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FHV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_metric_performance('FDC_FLV', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-500,100], watersheds_local=all_watersheds, camels_graph_local=catmt_graph, metric_label='FLV', extend='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('NSE', ds, lead_time=1, cmap_name='RdYlBu', min_max=[-1,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_metric_performance('F1_score', ds, lead_time=1, cmap_name='RdYlBu', min_max=[0,1], watersheds_local=all_watersheds, camels_graph_local=catmt_graph)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_comparison(metric_name, metric_label, min_max=None):\n",
    "    # ds_camelsus = xr.open_dataset(filepath(2, 'camelsus'))\n",
    "    # ds_camelsind = xr.open_dataset(filepath(2, 'camelsind'))\n",
    "    # ds_hysets = xr.open_dataset(filepath(2, 'hysets'))\n",
    "\n",
    "    ds_camelsus = xr.open_dataset(filepath(2, 'camelsus'))\n",
    "    ds_camelsind = xr.open_dataset(filepath(2, 'camelsind'))\n",
    "    ds_hysets = xr.open_dataset(filepath(2, 'hysets'))\n",
    "\n",
    "    if metric_label is None:\n",
    "        metric_label = metric_name\n",
    "\n",
    "    datasets = {\n",
    "        'CAMELS-US': ds_camelsus,\n",
    "        'CAMELS-IND': ds_camelsind,\n",
    "        'HYSETS': ds_hysets\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        'CAMELS-US': 'blue',\n",
    "        'CAMELS-IND': 'orange',\n",
    "        'HYSETS': 'green'\n",
    "    }\n",
    "\n",
    "    offsets = {\n",
    "        'CAMELS-US': 0.0,\n",
    "        'CAMELS-IND': 0.15,\n",
    "        'HYSETS': -0.15\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5), dpi=600)\n",
    "\n",
    "    for key, ds in datasets.items():\n",
    "        metric_values = ds[metric_name].values\n",
    "        # Clip to min_max if provided\n",
    "        if min_max is not None:\n",
    "            metric_values = np.clip(metric_values, min_max[0], min_max[1])\n",
    "        lead_times = ds.lead_time.values\n",
    "\n",
    "        median_metric = np.nanmedian(metric_values, axis=1)\n",
    "        q1 = np.nanpercentile(metric_values, 25, axis=1)\n",
    "        q3 = np.nanpercentile(metric_values, 75, axis=1)\n",
    "\n",
    "        lower_err = median_metric - q1\n",
    "        upper_err = q3 - median_metric\n",
    "        # plt.fill_between(\n",
    "        #     lead_times + offsets[key], \n",
    "        #     q1, \n",
    "        #     q3, \n",
    "        #     color=colors[key], \n",
    "        #     alpha=0.15\n",
    "        # )\n",
    "\n",
    "        plt.errorbar(\n",
    "            lead_times + offsets[key], \n",
    "            median_metric, \n",
    "            yerr=[lower_err, upper_err],\n",
    "            fmt='-o', \n",
    "            capsize=15, \n",
    "            color=colors[key], \n",
    "            label=key, \n",
    "            alpha = 0.5, \n",
    "            markeredgewidth=2, \n",
    "            elinewidth=2\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Lead Time (Days)\", fontsize=12)\n",
    "    plt.ylabel(metric_label, fontsize=12)\n",
    "    # plt.ylim(min_max)\n",
    "    plt.legend(\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        loc = 'lower center',\n",
    "        ncol=3,\n",
    "        # labelspacing=1.5\n",
    "        )\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(ticks=lead_times, labels=lead_times+1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Set the fontsize of labels and ticks\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    ax.xaxis.label.set_size(32)\n",
    "    ax.yaxis.label.set_size(32)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('NSE', None, min_max=[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('F1_score', 'F1 Score of \\ncaptured peaks', min_max=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('KGE', None, min_max=[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('PBIAS', None, min_max=[-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('PearsonR', 'r', min_max=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('RMSE', None, min_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('FDC_FHV', 'FHV', min_max=[-100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('FDC_FLV', 'FLV', min_max=[-500,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Plots Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"Historical\": (2, \"surr\"),\n",
    "    \"Filtered ERA5 variables\": (1, \"lat\"),\n",
    "    \"GPM-Final\": (2, \"lat\"),\n",
    "    \"No Meteorological\": (3, \"lat\"),\n",
    "    \"Using HRES\": (4, \"lat\")\n",
    "}\n",
    "\n",
    "regions = {\n",
    "    \"CAMELS-US\": \"camelsus\",\n",
    "    \"HYSETS\": \"hysets\",\n",
    "    \"CAMELS-IND\": \"camelsind\"\n",
    "}\n",
    "\n",
    "# filepath = lambda x, region: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure03', f'v{x}_surr_{region}_test_metrics.nc')\n",
    "filepath = lambda x, region, mode: os.path.join('/home/sarth/rootdir/workdir/projects/Paper_Data_Latency/Revised_Figure05', f'v{x}_{mode}_{region}_test_metrics.nc')\n",
    "\n",
    "def plot_metric_comparison(metric_name, metric_label, min_max=None, region='CAMELS-US'):\n",
    "    ds_hist = xr.open_dataset(filepath(experiments['Historical'][0], regions[region], experiments['Historical'][1]))\n",
    "    ds_filERA5 = xr.open_dataset(filepath(experiments['Filtered ERA5 variables'][0], regions[region], experiments['Filtered ERA5 variables'][1]))\n",
    "    ds_GPMFinal = xr.open_dataset(filepath(experiments['GPM-Final'][0], regions[region], experiments['GPM-Final'][1]))\n",
    "    ds_NoMet = xr.open_dataset(filepath(experiments['No Meteorological'][0], regions[region], experiments['No Meteorological'][1]))\n",
    "    ds_HRES = xr.open_dataset(filepath(experiments['Using HRES'][0], regions[region], experiments['Using HRES'][1]))\n",
    "\n",
    "    if metric_label is None:\n",
    "        metric_label = metric_name\n",
    "\n",
    "    datasets = {\n",
    "        'Historical': ds_hist,\n",
    "        'Filtered ERA5 variables': ds_filERA5,\n",
    "        'GPM-Final': ds_GPMFinal,\n",
    "        'No Meteorological': ds_NoMet,\n",
    "        'Using HRES': ds_HRES,\n",
    "    }\n",
    "\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    norm_colors = cmap(np.linspace(0, 1, 10))\n",
    "\n",
    "    colors = {\n",
    "        'Historical': norm_colors[0],\n",
    "        'Filtered ERA5 variables': norm_colors[1],\n",
    "        'GPM-Final': norm_colors[2],\n",
    "        'No Meteorological': norm_colors[3],\n",
    "        'Using HRES': norm_colors[4]\n",
    "    }\n",
    "\n",
    "    offsets = {\n",
    "        'Historical': 0.0,\n",
    "        'Filtered ERA5 variables': -0.10,\n",
    "        'GPM-Final': -0.20,\n",
    "        'No Meteorological': 0.10,\n",
    "        'Using HRES': 0.20\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5), dpi=600)\n",
    "\n",
    "    for key, ds in datasets.items():\n",
    "        metric_values = ds[metric_name].values\n",
    "        # Clip to min_max if provided\n",
    "        if min_max is not None:\n",
    "            metric_values = np.clip(metric_values, min_max[0], min_max[1])\n",
    "        lead_times = ds.lead_time.values\n",
    "\n",
    "        median_metric = np.nanmedian(metric_values, axis=1)\n",
    "        q1 = np.nanpercentile(metric_values, 25, axis=1)\n",
    "        q3 = np.nanpercentile(metric_values, 75, axis=1)\n",
    "\n",
    "        lower_err = median_metric - q1\n",
    "        upper_err = q3 - median_metric\n",
    "        # plt.fill_between(\n",
    "        #     lead_times + offsets[key], \n",
    "        #     q1, \n",
    "        #     q3, \n",
    "        #     color=colors[key], \n",
    "        #     alpha=0.15\n",
    "        # )\n",
    "\n",
    "        plt.errorbar(\n",
    "            lead_times + offsets[key], \n",
    "            median_metric, \n",
    "            yerr=[lower_err, upper_err],\n",
    "            fmt='-o', \n",
    "            capsize=15, \n",
    "            color=colors[key], \n",
    "            label=key, \n",
    "            alpha = 0.5, \n",
    "            markeredgewidth=2, \n",
    "            elinewidth=2\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Lead Time (Days)\", fontsize=12)\n",
    "    plt.ylabel(metric_label, fontsize=12)\n",
    "    # plt.ylim(min_max)\n",
    "    plt.legend(\n",
    "        bbox_to_anchor=(0.5, 1),\n",
    "        loc = 'lower center',\n",
    "        ncol=5,\n",
    "        # labelspacing=1.5\n",
    "        )\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(ticks=lead_times, labels=lead_times+1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Set the fontsize of labels and ticks\n",
    "    ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    ax.xaxis.label.set_size(32)\n",
    "    ax.yaxis.label.set_size(32)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_name = 'CAMELS-US'\n",
    "# region_name = 'HYSETS'\n",
    "region_name = 'CAMELS-IND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric_comparison('NSE', None, min_max=[-1, 1], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric_comparison('F1_score', 'F1 Score of \\ncaptured peaks', min_max=[0, 1], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('KGE', None, min_max=[-1, 1], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('PBIAS', None, min_max=[-100, 100], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('PearsonR', 'r', min_max=[0, 1], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_comparison('RMSE', None, min_max=None, region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric_comparison('FDC_FHV', 'FHV', min_max=[-100,100], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric_comparison('FDC_FLV', 'FLV', min_max=[-500,100], region=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
